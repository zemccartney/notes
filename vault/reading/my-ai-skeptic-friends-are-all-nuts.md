---
source: https://fly.io/blog/youre-all-nuts/
author: Thomas Ptacek
tags:
  - ai
  - programming
---
An upsetting piece, will have to sit with it, read up on counterarguments, but I think I generally agree, find the premise persuasive: most arguments against LLMs in the **software development space** (I appreciate the author takes care to scope argument to his field, not extend to visual arts) are not about LLMs proper, their quality of work and utility, or even their social or cultural consequences, but rather projecting insecurity and fear of uncertainty, rapid change.

Might not be exactly what the author meant, but how i'm internalizing, how this landed for me, my feelings around AI, the struggle over the last year plus with adopting it and feeling constant emotional whiplash and dread over future career prospects. A corollary i wish they'd have added: it's totally ok to feel insecure and scared of AI's impact. It's a massive shift, it's a threat to career work in software. That shit should be scary. It should be frustrating. But it's disingenuous, and for the arguments raised around respect for IP and sanctity of human labor, hypocritical and disrespectful, to try to mask and elevate your own feelings behind arguments based on some imagined protected status for software engineering. It's a conflict. A miserable one. Acknowledging that it's ok to be miserable doesn't get you shit, but I guess it's something.

AI is here and incredibly valuable in software development and skills with utilizing it are now table stakes for surviving in the industry. Whether this is good, whether you like this, whatever the consequences, this is how the tide's pulling, important to be realistic about that

Some quotes I enjoyed:

> For the last month or so, Gemini 2.5 has been my go-to †. Almost nothing it spits out for me merges without edits. I’m sure there’s a skill to getting a SOTA model to one-shot a feature-plus-merge! But I don’t care. I like moving the code around and chuckling to myself while I delete all the stupid comments. I have to read the code line-by-line anyways.

god, the stupid comments. I work the same, moving around, tweaking. Just the act of light engagement helps me think about the LLM's output, but also deepens my thinking of the problem at play.

> We’re a field premised on automating other people’s jobs away. “Productivity gains,” say the economists. You get what that means, right? Fewer people doing the same stuff. ... LLMs really might displace many software developers. That’s not a high horse we get to ride. Our jobs are just as much in tech’s line of fire as everybody else’s have been for the last 3 decades.

So easy to live within the industry bubble. What do people outside tech think of us? Answer might not be so flattering

> Sometimes, gnarly stuff needs doing. But you don’t wanna do it. So you refactor unit tests, soothing yourself with the lie that you’re doing real work. But an LLM can be told to go refactor all your unit tests. An agent can occupy itself for hours putzing with your tests in a VM and come back later with a PR. If you listen to me, you’ll know that. You’ll feel worse yak-shaving. You’ll end up doing… real work.

AI to prevent self-soothing (procrastinating); push to self-reflect: when are you avoiding the Real Work? when you are, set the robot on the task you were using to procrastinate. 